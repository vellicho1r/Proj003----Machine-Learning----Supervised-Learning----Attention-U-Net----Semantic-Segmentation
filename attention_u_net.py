# -*- coding: utf-8 -*-
"""Attention U-Net.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_Zb4iXI3r5Q0GE-lfkLipNu0xdgBlihg

**1.1. Install Essentials**
"""

from IPython.display import clear_output    #Because of the Error : NameError: name 'clear_output' is not defined

!pip install tensorflow_addons
!pip install keras
!pip install segmentation-models
!pip install tf_explain
clear_output()

"""**1.2. Import Essentials**"""

#Because of the Error AttributeError: module 'keras.utils' has no attribute 'generic_utils'

!pip install -U -q segmentation-models
!pip install -q tensorflow==2.2.1
!pip install -q keras==2.5
import os
os.environ["SM_FRAMEWORK"] = "tf.keras"

from tensorflow import keras
import segmentation_models as sm

!pip install segmentation-models
import tensorflow
import keras
from keras.models import Model
from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda, Activation
from tensorflow.keras import models, layers, regularizers
from tensorflow.keras import backend as K
import numpy as np
import nibabel as nib
import glob
import tensorflow as tf
from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import train_test_split
from datetime import datetime
from segmentation_models.losses import bce_jaccard_loss
from segmentation_models.losses import bce_dice_loss
from segmentation_models.losses import binary_focal_dice_loss
from keras.losses import binary_crossentropy
#from keras.losses import dice_ce
import keras.backend as K
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
#from res_unet_model import multi_unet_model
from tensorflow.keras.optimizers import Adam
import tensorflow as tf
import random
import glob
from matplotlib import pyplot as plt
import keras
import numpy as np
import os
import math

"""**1.3. Drive Mount Dataset : Nifti images + Nifti masks**"""

import tensorflow as tf
from tensorflow.keras.preprocessing.image import img_to_array, load_img
from skimage.transform import resize
import numpy as np

def load_image(image, SIZE):
    return np.round(resize(img_to_array(load_img(image))/255.,(SIZE, SIZE)),4)

def load_images(image_paths, SIZE, mask=False, trim=None):
    if trim is not None:
        image_paths = image_paths[:trim]

    if mask:
        images = np.zeros(shape=(len(image_paths), SIZE, SIZE, 1))
    else:
        images = np.zeros(shape=(len(image_paths), SIZE, SIZE, 3))

    for i,image in enumerate(image_paths):
        img = load_image(image,SIZE)
        if mask:
            images[i] = img[:,:,:1]
        else:
            images[i] = img

    return images

def show_mask_only(mask, cmap=None, alpha=0.4):
    plt.imshow(tf.squeeze(mask), cmap=cmap, alpha=alpha)
    plt.axis('off')

from google.colab import drive
drive.mount('/content/drive')

import pathlib

data_dir = '/content/drive/MyDrive/HarP'
path_dir = pathlib.Path('/content/drive/MyDrive/imageandsegment/')

class_names = np.array(sorted([item.name for item in path_dir.glob('*')]))
print(class_names)
IMAGE_SIZE= (256,256)
import glob   #Because of the Error : function has no Attribute glob


image_paths = sorted(glob.glob(('/content/drive/MyDrive/imageandsegment/training/image/*')))
mask_paths = sorted(glob.glob(('/content/drive/MyDrive/imageandsegment/training/mask/*')))

#Approximate Running time = 4min

SIZE = 256

images = load_images(image_paths, SIZE)
masks = load_images(mask_paths, SIZE, mask=True)

"""**2.1. Defining Attention UNet for Semantic Segmentation ----> Encoder Part**"""

from tensorflow.keras.layers import Layer   #Because of the error : NameError: name 'Layer' is not defined

#Encoder

class EncoderBlock(Layer):

    def __init__(self, filters, rate, pooling=True, **kwargs):
        super(EncoderBlock, self).__init__(**kwargs)

        self.filters = filters
        self.rate = rate
        self.pooling = pooling

        self.c1 = Conv2D(filters, kernel_size=3, strides=1, padding='same', activation='relu', kernel_initializer='he_normal')
        self.drop = Dropout(rate)
        self.c2 = Conv2D(filters, kernel_size=3, strides=1, padding='same', activation='relu', kernel_initializer='he_normal')
        self.pool = MaxPool2D()

    def call(self, X):
        x = self.c1(X)
        x = self.drop(x)
        x = self.c2(x)
        if self.pooling:
            y = self.pool(x)
            return y, x
        else:
            return x

    def get_config(self):
        base_config = super().get_config()
        return {
            **base_config,
            "filters":self.filters,
            'rate':self.rate,
            'pooling':self.pooling
        }

"""**2.2. Decoder Part**"""

#Decoder
class DecoderBlock(Layer):

    def __init__(self, filters, rate, **kwargs):
        super(DecoderBlock, self).__init__(**kwargs)

        self.filters = filters
        self.rate = rate

        self.up = UpSampling2D()
        self.net = EncoderBlock(filters, rate, pooling=False)

    def call(self, X):
        X, skip_X = X
        x = self.up(X)
        c_ = concatenate([x, skip_X])
        x = self.net(c_)
        return x

    def get_config(self):
        base_config = super().get_config()
        return {
            **base_config,
            "filters":self.filters,
            'rate':self.rate,
        }

"""**2.3. Attention Gate**"""

#AttentionGate
class AttentionGate(Layer):

    def __init__(self, filters, bn, **kwargs):
        super(AttentionGate, self).__init__(**kwargs)

        self.filters = filters
        self.bn = bn

        self.normal = Conv2D(filters, kernel_size=3, padding='same', activation='relu', kernel_initializer='he_normal')
        self.down = Conv2D(filters, kernel_size=3, strides=2, padding='same', activation='relu', kernel_initializer='he_normal')
        self.learn = Conv2D(1, kernel_size=1, padding='same', activation='sigmoid')
        self.resample = UpSampling2D()
        self.BN = BatchNormalization()

    def call(self, X):
        X, skip_X = X

        x = self.normal(X)
        skip = self.down(skip_X)
        x = Add()([x, skip])
        x = self.learn(x)
        x = self.resample(x)
        f = Multiply()([x, skip_X])
        if self.bn:
            return self.BN(f)
        else:
            return f
        # return f

    def get_config(self):
        base_config = super().get_config()
        return {
            **base_config,
            "filters":self.filters,
            "bn":self.bn
        }

from keras.callbacks import Callback    #Because Callback was not defined

from keras.layers import Add    #Because of the NameError : name 'Add' is not defined

from keras.layers import Multiply #Same for Multiply

from tensorflow.keras.layers import Conv2D, MaxPool2D
#Because of the Error : NameError: name 'MaxPool2D' is not defined

#class ShowProgress(Callback):
    def on_epoch_end(self, epochs, logs=None):
        id = np.random.randint(200)
        exp = GradCAM()
        image = images[id]
        mask = masks[id]
        pred_mask = self.model.predict(image[np.newaxis,...])
        cam = exp.explain(
            validation_data=(image[np.newaxis,...], mask),
            class_index=1,
            layer_name='Attention4',
            model=self.model
        )
        plt.figure(figsize=(10,5))

        plt.subplot(1,2,1)
        plt.title("Original Mask")
        show_mask_only(mask, cmap='gray')

        plt.subplot(1,2,2)
        plt.title("Predicted Mask")
        show_mask_only(pred_mask, cmap='gray')

        plt.tight_layout()
        plt.show()

# Metrics
from keras.metrics import MeanIoU     #Because of the Error NameError: name 'MeanIoU' is not defined

# Inputs
input_layer = Input(shape=images.shape[-3:])

# Encoder
p1, c1 = EncoderBlock(32,0.1, name="Encoder1")(input_layer)
p2, c2 = EncoderBlock(64,0.1, name="Encoder2")(p1)
p3, c3 = EncoderBlock(128,0.2, name="Encoder3")(p2)
p4, c4 = EncoderBlock(256,0.2, name="Encoder4")(p3)

# Encoding
encoding = EncoderBlock(512,0.3, pooling=False, name="Encoding")(p4)

# Attention + Decoder

a1 = AttentionGate(256, bn=True, name="Attention1")([encoding, c4])
d1 = DecoderBlock(256,0.2, name="Decoder1")([encoding, a1])

a2 = AttentionGate(128, bn=True, name="Attention2")([d1, c3])
d2 = DecoderBlock(128,0.2, name="Decoder2")([d1, a2])

a3 = AttentionGate(64, bn=True, name="Attention3")([d2, c2])
d3 = DecoderBlock(64,0.1, name="Decoder3")([d2, a3])


a4 = AttentionGate(32, bn=True, name="Attention4")([d3, c1])
d4 = DecoderBlock(32,0.1, name="Decoder4")([d3, a4])

# Output
output_layer = Conv2D(1, kernel_size=1, activation='sigmoid', padding='same')(d4)

# Model
model = Model(
    inputs=[input_layer],
    outputs=[output_layer]
)

model.summary()

# Callbacks
cb = [
    # EarlyStopping(patience=3, restore_best_weight=True), # With Segmentation I trust on eyes rather than on metrics
    ModelCheckpoint("AttentionCustomUNet.h5", save_best_only=True),
    ShowProgress()
]

import tensorflow as tf

def dice_coeff(y_true, y_pred):
    smooth = 1e-15
    intersection = tf.reduce_sum(y_true * y_pred)
    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred)
    dice = (2. * intersection + smooth) / (union + smooth)
    return dice

model.compile(
    loss=tf.keras.losses.BinaryCrossentropy(),
    optimizer='adam',
    metrics=['accuracy', dice_coeff, tf.keras.metrics.MeanIoU(num_classes=2, name='IoU')]
)

import tensorflow_addons as tfa

from tf_explain.core.grad_cam import GradCAM
#Because of the Error NameError: name 'GradCAM' is not defined

from sklearn.model_selection import train_test_split

X_train, X_val, y_train, y_val = train_test_split(images, masks, test_size=0.2, random_state=42)


# Config Training
BATCH_SIZE = 32
SPE = len(X_train) // BATCH_SIZE

# Training
results = model.fit(
    X_train, y_train,
    validation_split=0.2,
    epochs=60, # 15 will be enough for a good Model for better model go with 20+
    steps_per_epoch=SPE,
    batch_size=BATCH_SIZE,
    callbacks=cb
)

loss, accuracy, iou, val_loss, val_accuracy, val_iou = results.history.values()

import cv2
import numpy as np

def get_mask_box(mask):
    img = np.uint8(mask[0, :, :, 0] * 255)

    _, binary = cv2.threshold(img, 200, 255, cv2.THRESH_BINARY)
    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    img_bgr = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)

    for contour in contours:
        x, y, w, h = cv2.boundingRect(contour)
        color = (0, 255, 0)
        cv2.rectangle(img_bgr, (x, y), (x + w, y + h), color, 2)

        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 0.5
        thickness = 1
        text_height = f'Height: {h}'
        text_width = f'Width: {w}'
        text_height_size = cv2.getTextSize(text_height, font, font_scale, thickness)[0]
        text_width_size = cv2.getTextSize(text_width, font, font_scale, thickness)[0]
        cv2.putText(img_bgr, text_height, (x, y - text_height_size[1]), font, font_scale, color, thickness, cv2.LINE_AA)
        cv2.putText(img_bgr, text_width, (x + w - text_width_size[0], y + h + text_width_size[1]), font, font_scale, color, thickness, cv2.LINE_AA)

    plt.imshow(img_bgr,cmap = None)
    plt.axis('off')

plt.figure(figsize=(20,25))
n=0
for i in range(1,(5*3)+1):
    plt.subplot(5,3,i)
    if n==0:
        id = np.random.randint(len(images))
        image = images[id]
        mask = masks[id]
        pred_mask = model.predict(image[np.newaxis,...])

        plt.title("Original Mask")
        show_mask(image, mask)
        n+=1
    elif n==1:
        plt.title("Predicted Mask")
        show_mask(image, pred_mask)
        n+=1
    elif n==2:
        pred_mask = (pred_mask>0.5).astype('float')
        plt.title("Processed Mask")
        show_mask(image, pred_mask)
        n=0
plt.tight_layout()
plt.show()

plt.figure(figsize=(20,25))
n=0
for i in range(1,(5*3)+1):
    plt.subplot(5,3,i)
    if n==0:
        id = np.random.randint(len(images))
        image = images[id]
        mask = masks[id]
        pred_mask = model.predict(image[np.newaxis,...])

        plt.title("Original Mask")
        show_mask(image, mask)
        n+=1
    elif n==1:
        plt.title("Predicted Mask")
        show_mask(image, pred_mask)
        n+=1
    elif n==2:
        pred_mask = (pred_mask>0.5).astype('float')
        plt.title("Processed Mask")
#         show_mask(image, pred_mask)
        get_mask_box(pred_mask)
        n=0
plt.tight_layout()
plt.show()

id = 12
image = images[id]
mask = model.predict(image[np.newaxis,...])
get_mask_box(mask)

import numpy as np
from sklearn.metrics import confusion_matrix, classification_report

# assume y_true is the true binary mask and y_pred is the predicted mask
# both have shape (num_samples, height, width, num_channels)
y_true = y_val
y_pred = model.predict(X_val)

# threshold the predicted mask to convert to binary values
y_true_bool = (y_true > 0.5).astype(bool)
cm = confusion_matrix(y_true_bool.flatten(), y_pred_thresh.flatten())
cr = classification_report(y_true_bool.flatten(), y_pred_thresh.flatten())

print("Confusion matrix:")
print(cm)
print("Classification report:")
print(cr)

#Plotting Model Loss (Training Loss and Validation Loss)

plt.plot(hist.history['loss'])
plt.plot(hist.history['val_loss'])
plt.title('2D U-Net Model Loss')
plt.ylabel('Loss')
plt.xlabel('Number of Epochs')
plt.legend(['Training Loss' , 'Validation Loss'], loc = 'upper right')
plt.show()

#Plotting Model Accuracy (Training Accuracy and Validation Accuracy)

plt.plot(hist.history['accuracy'])
plt.plot(hist.history['val_accuracy'])
plt.title('2D U-Net Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Number of Epochs')
plt.legend(['Training Loss' , 'Validation Loss'], loc = 'lower right')
plt.show()

#Plotting Model Dice Similarity Coefficient

plt.plot(hist.history['dice_coef1'])
plt.plot(hist.history['val_dice_coef1'])
plt.title('2D Model Dice Similarity Coefficient')
plt.ylabel('Dice Similarity Coefficient')
plt.xlabel('Number of Epochs')
plt.legend(['Trainining DSC' , 'Validation DSC'], loc = 'lower right')
plt.show()

#Plotting Intersection over Union

plt.plot(hist.history['loss'])
plt.plot(hist.history['val_loss'])
plt.title('2D U-Net Model IoU')
plt.ylabel('Intersection over Union')
plt.xlabel('Number of Epochs')
plt.legend(['Training IoU' , 'Validation IoU'], loc = 'upper right')
plt.show()

